{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Reinforcement Learning Sample\n",
    "\n",
    "Azure ML reinforcement learning is a managed service for running distributed RL (reinforcement learning) simulation and training using the Ray framework.\n",
    "\n",
    "This example uses Ray rllib to train a Pong playing agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ML Core imports\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.tensorboard import Tensorboard\n",
    "\n",
    "# Azure ML Reinforcement Learning imports\n",
    "from azureml.contrib.train.rl import ReinforcementLearningEstimator, Ray\n",
    "from azureml.contrib.train.rl import WorkerConfiguration\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Azure ML Workspace\n",
    "\n",
    "Get the Azure ML workspace you created in the 'Workspace Setup' notebook.\n",
    "\n",
    "Currently, the workspace must be in one of the following regions: `eastus`, `westeurope`, and `westus2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the name of your vnet\n",
    "\n",
    "The resource group you use must contain a vnet.  Specify the name of the vnet here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnet_name = 'your_vnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define head computing cluster\n",
    "\n",
    "In this example, we show how to set up separate computing clusters for the Ray head and Ray workers.  First we define the head cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for the Ray head cluster\n",
    "compute_name = 'head-gpu'\n",
    "compute_min_nodes = 0\n",
    "compute_max_nodes = 2\n",
    "\n",
    "# This example uses GPU VM. For using CPU VM, set SKU to STANDARD_D2_V2\n",
    "vm_size = 'STANDARD_NC6'\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(f'found compute target. just use it {compute_name}')\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes,\n",
    "                                                               vnet_resourcegroup_name = ws.resource_group,\n",
    "                                                               vnet_name = vnet_name,\n",
    "                                                               subnet_name = 'default')\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define worker computing cluster\n",
    "\n",
    "Now create a computer cluster for the Ray workers.  These are virtual machines to run worker jobs.  Ray can distribute multiple worker tasks on each worker virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for your Ray worker cluster\n",
    "worker_compute_name = 'worker-cpu'\n",
    "worker_compute_min_nodes = 0 \n",
    "worker_compute_max_nodes = 5\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "worker_vm_size = 'STANDARD_D2_V2'\n",
    "\n",
    "# Create the compute target if it hasn't been created already\n",
    "if worker_compute_name in ws.compute_targets:\n",
    "    worker_compute_target = ws.compute_targets[worker_compute_name]\n",
    "    if worker_compute_target and type(worker_compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it {worker_compute_name}')\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = worker_vm_size,\n",
    "                                                                min_nodes = worker_compute_min_nodes, \n",
    "                                                                max_nodes = worker_compute_max_nodes,\n",
    "                                                               vnet_resourcegroup_name = ws.resource_group,\n",
    "                                                               vnet_name = vnet_name,\n",
    "                                                               subnet_name = 'default')\n",
    "\n",
    "    # create the cluster\n",
    "    worker_compute_target = ComputeTarget.create(ws, worker_compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    worker_compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(worker_compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure ML Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='rllib-pong'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Reinforcement Learning Estimator\n",
    "\n",
    "The `ReinforcementLearningEstimator` is used to submit a job to Azure Machine Learning to start the Ray experiment run.\n",
    "\n",
    "You define a `WorkerCOnfiguration` to point to your worker compute cluster, the number of virtual machines you want to use, whether to use GPU, and any dependencies needed by the workers.\n",
    "\n",
    "In our case, we define the same PIP packages as dependencies for both head and worker notes.  For this problem, the game simulations will run directly on the worker compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pip packages we will use for both head and worker\n",
    "pip_packages={\n",
    "}\n",
    "\n",
    "# Specify the Ray worker configuration\n",
    "worker_conf = WorkerConfiguration(\n",
    "    \n",
    "    # Azure ML compute cluster to run Ray workers\n",
    "    compute_target=worker_compute_target, \n",
    "    \n",
    "    # Number of workers\n",
    "    node_count = 4,\n",
    "    \n",
    "    # GPU\n",
    "    use_gpu=False, \n",
    "    \n",
    "    # PIP packages to use\n",
    "    pip_packages=pip_packages\n",
    ")\n",
    "\n",
    "estimator = ReinforcementLearningEstimator(\n",
    "    \n",
    "    # Location of source files\n",
    "    source_directory='files',\n",
    "    \n",
    "    # Python script file\n",
    "    entry_script=\"rllib-pong.py\",\n",
    "    \n",
    "    # Parameters to pass to the script file\n",
    "    # Define above.\n",
    "    script_params={},\n",
    "    \n",
    "    # The Azure ML compute target set up for Ray head nodes\n",
    "    compute_target=compute_target,\n",
    "    \n",
    "    # Pip packages\n",
    "    pip_packages=pip_packages,\n",
    "    \n",
    "    # GPU usage\n",
    "    use_gpu=True,\n",
    "    \n",
    "    # RL framework.  Currently must be Ray.\n",
    "    rl_framework=Ray(version=\"0.7.2\"),\n",
    "    \n",
    "    # Ray worker configuration defined above.\n",
    "    worker_configuration=worker_conf,\n",
    "    \n",
    "    # Simulator configuration (future use)\n",
    "    simulator_configuration=None,\n",
    "    \n",
    "    # How long to wait for job to start\n",
    "    job_queue_timeout=3600,\n",
    "    \n",
    "    # How long to wait for whole cluster to start\n",
    "    cluster_coordination_timeout_seconds=3600,\n",
    "    \n",
    "    # Maximum time for the whole Ray job to run\n",
    "    # This will cut off the run after an hour\n",
    "    max_run_duration_seconds=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the estimator to start experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor experiment\n",
    "\n",
    "Azure ML provides a Jupyter widget to show the real-time status of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop experiment\n",
    "\n",
    "To cancel the run, call run.cancel().\n",
    "\n",
    "If you want to cancel the run from the Azure Workspace portal, cancel one of the child runs.  \n",
    "Canceling a ReinforcementLearningEstimator run in the portal is not currently supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "You can also monitor details of your experiment with Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to wait until the Ray worker run is in the Running state before you can start Tensorboard.\n",
    "tb = Tensorboard([list(run.get_children())[0]])\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Tensorboard\n",
    "tb.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

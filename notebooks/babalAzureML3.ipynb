{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "metadata": {},
      "source": [
        "import os\n",
        "import urllib\n",
        "import shutil\n",
        "import azureml\n",
        "import pandas as pd\n",
        "\n",
        "from azureml.core import Experiment\n",
        "from azureml.core import Workspace, Run\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core import Experiment, Workspace, Run, Dataset"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [],
      "metadata": {},
      "source": [
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Run\n",
        "from azureml.core.model import Model\n",
        "from azureml.core import Workspace, Dataset\n",
        "from azureml.core import Experiment\n",
        "from azureml.core import Workspace, Run\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "Found workspace mlopsdev at location centralus"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import os\n",
        "from azureml.core.authentication import ServicePrincipalAuthentication\n",
        " \n",
        "svc_pr_password = os.environ.get(\"AZUREML_PASSWORD\")\n",
        " \n",
        "svc_pr = ServicePrincipalAuthentication(\n",
        "    tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
        "    service_principal_id=\"8a3ddafe-6dd6-48af-867e-d745232a1833\",\n",
        "    service_principal_password=\"1fY58u0dpP1Yg-i.A~rUp_iz04RxWUFSwv\")\n",
        " \n",
        "ws = Workspace(\n",
        "    subscription_id=\"c46a9435-c957-4e6c-a0f4-b9a597984773\",\n",
        "    resource_group=\"mlops\",\n",
        "    workspace_name=\"mlopsdev\",\n",
        "    auth=svc_pr\n",
        "    )\n",
        " \n",
        "print(\"Found workspace {} at location {}\".format(ws.name, ws.location))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [],
      "metadata": {},
      "source": [
        "project_folder = './diabetes-project'\n",
        "os.makedirs(project_folder, exist_ok=True)\n",
        "\n",
        "experiment = Experiment(workspace=ws, name='diabetes-model')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [],
      "metadata": {},
      "source": [
        "output_folder = './outputs'\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [],
      "metadata": {},
      "source": [
        "result_folder = './results'\n",
        "os.makedirs(result_folder, exist_ok=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [],
      "metadata": {},
      "source": [
        "df = pd.read_csv('https://mlopssa.blob.core.windows.net/chd-dataset/framingham.csv')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "Index(['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n       'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "df.columns"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "metadata": {},
      "source": [
        "# create a boolean array of smokers\n",
        "smoke = (df['currentSmoker']==1)\n",
        "# Apply mean to NaNs in cigsPerDay but using a set of smokers only\n",
        "df.loc[smoke,'cigsPerDay'] = df.loc[smoke,'cigsPerDay'].fillna(df.loc[smoke,'cigsPerDay'].mean())\n",
        "\n",
        "# Fill out missing values\n",
        "df['BPMeds'].fillna(0, inplace = True)\n",
        "df['glucose'].fillna(df.glucose.mean(), inplace = True)\n",
        "df['totChol'].fillna(df.totChol.mean(), inplace = True)\n",
        "df['education'].fillna(1, inplace = True)\n",
        "df['BMI'].fillna(df.BMI.mean(), inplace = True)\n",
        "df['heartRate'].fillna(df.heartRate.mean(), inplace = True)\n",
        "\n",
        "# Features and label\n",
        "features = df.iloc[:,:-1]\n",
        "result = df.iloc[:,-1] # the last column is what we are about to forecast"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Train & Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state = 14)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=2, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n            oob_score=False, random_state=0, verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
        "clf.fit(X_train, y_train)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "Found existing cluster, use it.\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "cpu_cluster_name = \"touringcluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D14_V2',\n",
        "                                                           max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
        "\n",
        "# Create a new runconfig object\n",
        "run_amlcompute = RunConfiguration()\n",
        "\n",
        "# Use the cpu_cluster you created above. \n",
        "run_amlcompute.target = cpu_cluster\n",
        "\n",
        "# Enable Docker\n",
        "run_amlcompute.environment.docker.enabled = True\n",
        "\n",
        "# Set Docker base image to the default CPU-based image\n",
        "run_amlcompute.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "\n",
        "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
        "run_amlcompute.environment.python.user_managed_dependencies = False\n",
        "\n",
        "# Specify CondaDependencies obj, add necessary packages\n",
        "run_amlcompute.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn'])"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "Overwriting $project_folder/train.py"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%writefile $project_folder/train.py\n",
        "\n",
        "import joblib\n",
        "import os\n",
        "import urllib\n",
        "import shutil\n",
        "import azureml\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from azureml.core import Experiment\n",
        "from azureml.core import Workspace, Run\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "from azureml.core.authentication import ServicePrincipalAuthentication\n",
        " \n",
        "svc_pr_password = \"1fY58u0dpP1Yg-i.A~rUp_iz04RxWUFSwv\"\n",
        " \n",
        "svc_pr = ServicePrincipalAuthentication(\n",
        "    tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
        "    service_principal_id=\"8a3ddafe-6dd6-48af-867e-d745232a1833\",\n",
        "    service_principal_password=\"1fY58u0dpP1Yg-i.A~rUp_iz04RxWUFSwv\")\n",
        " \n",
        "ws = Workspace(\n",
        "    subscription_id=\"c46a9435-c957-4e6c-a0f4-b9a597984773\",\n",
        "    resource_group=\"mlops\",\n",
        "    workspace_name=\"mlopsdev\",\n",
        "    auth=svc_pr\n",
        "    )\n",
        "\n",
        "#dataset = Dataset.get_by_name(ws, name='touringdataset')\n",
        "#dataset.to_pandas_dataframe()\n",
        "data_complete = df = pd.read_csv('https://mlopssa.blob.core.windows.net/chd-dataset/framingham.csv')\n",
        "\n",
        "# create a boolean array of smokers\n",
        "smoke = (df['currentSmoker']==1)\n",
        "# Apply mean to NaNs in cigsPerDay but using a set of smokers only\n",
        "df.loc[smoke,'cigsPerDay'] = df.loc[smoke,'cigsPerDay'].fillna(df.loc[smoke,'cigsPerDay'].mean())\n",
        "\n",
        "# Fill out missing values\n",
        "df['BPMeds'].fillna(0, inplace = True)\n",
        "df['glucose'].fillna(df.glucose.mean(), inplace = True)\n",
        "df['totChol'].fillna(df.totChol.mean(), inplace = True)\n",
        "df['education'].fillna(1, inplace = True)\n",
        "df['BMI'].fillna(df.BMI.mean(), inplace = True)\n",
        "df['heartRate'].fillna(df.heartRate.mean(), inplace = True)\n",
        "\n",
        "# Features and label\n",
        "features = df.iloc[:,:-1]\n",
        "result = df.iloc[:,-1] # the last column is what we are about to forecast\n",
        "\n",
        "# Train & Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state = 14)\n",
        "\n",
        "# RandomForest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Create a selector object that will use the random forest classifier to identify\n",
        "# features that have an importance of more than 0.12\n",
        "sfm = SelectFromModel(clf, threshold=0.12)\n",
        "\n",
        "# Train the selector\n",
        "sfm.fit(X_train, y_train)\n",
        "\n",
        "# Features selected\n",
        "featureNames = list(features.columns.values) # creating a list with features' names\n",
        "print(\"Feature names:\")\n",
        "for featureNameListindex in sfm.get_support(indices=True):\n",
        "    print(featureNames[featureNameListindex])\n",
        "\n",
        "# Feature importance\n",
        "importances = clf.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# With only imporant features. Can check X_important_train.shape[1]\n",
        "X_important_train = sfm.transform(X_train)\n",
        "X_important_test = sfm.transform(X_test)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
        "rfc.fit(X_important_train, y_train)\n",
        "\n",
        "\n",
        "#joblib.dump(rfc, \"/outputs/model.joblib\")\n",
        "os.makedirs('./outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=rfc, filename='./outputs/sklearn_diabetes_model.pkl')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.train.sklearn import SKLearn\n",
        "\n",
        "# script_params = {\n",
        "#     '--kernel': 'linear',\n",
        "#     '--penalty': 1.0,\n",
        "# }\n",
        "\n",
        "estimator = SKLearn(source_directory=project_folder, \n",
        "#                     script_params=script_params,\n",
        "                    compute_target=cpu_cluster,\n",
        "                    entry_script='train.py',\n",
        "                    pip_packages=['joblib']\n",
        "                   )"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "status": "error",
          "execution_count": 42,
          "data": null,
          "ename": "TrainingException",
          "evalue": "TrainingException:\n\tMessage: /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\n\tInnerException ExperimentExecutionException:\n\tMessage: /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\"\n    }\n}\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\"\n    }\n}",
          "traceback": [
            "TrainingException : TrainingException:\n\tMessage: /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\n\tInnerException ExperimentExecutionException:\n\tMessage: /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\"\n    }\n}\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\"\n    }\n}",
            "Traceback (most recent call last):\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/azureml/core/experiment.py\", line 202, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/azureml/train/_estimator_helper.py\", line 70, in _estimator_submit_method\n    experiment_run = estimator._fit(workspace, experiment_name)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/azureml/train/estimator/_mml_base_estimator.py\", line 155, in _fit\n    return self._submit(workspace, experiment_name, telemetry_values)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/azureml/train/estimator/_mml_base_estimator.py\", line 149, in _submit\n    raise TrainingException(e.message, inner_exception=e) from None\n",
            "azureml.exceptions._azureml_exception.TrainingException: TrainingException:\n\tMessage: /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\n\tInnerException ExperimentExecutionException:\n\tMessage: /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\"\n    }\n}\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1593949515275_0003/container_1593949515275_0003_01_000001/diabetes-project/train.py script path doesn't exist. The script should be inside the project folder\"\n    }\n}\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "run = experiment.submit(estimator)\n",
        "run.wait_for_completion(show_output=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "print(run.get_metrics())"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(run).show()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# register model\n",
        "model = run.register_model(model_name='sklearn_diabetes',\n",
        "                           model_path='outputs/sklearn_diabetes_model.pkl')\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [],
      "attachments": {}
    }
  ]
}
{"cells":[{"cell_type":"code","source":["# Check core SDK version number\r\n","import azureml.core\r\n","\r\n","print(\"SDK version:\", azureml.core.VERSION)"],"outputs":[{"output_type":"stream","name":"stdout","text":["SDK version: 1.6.0\n"]}],"execution_count":1,"metadata":{}},{"cell_type":"code","source":["from azureml.core import Workspace, Experiment\r\n","\r\n","ws = Workspace.from_config()\r\n","print('Workspace name: ' + ws.name, \r\n","      'Azure region: ' + ws.location, \r\n","      'Subscription id: ' + ws.subscription_id, \r\n","      'Resource group: ' + ws.resource_group, sep = '\\n')"],"outputs":[{"output_type":"stream","name":"stdout","text":["Workspace name: mlopsdev\n","Azure region: centralus\n","Subscription id: c46a9435-c957-4e6c-a0f4-b9a597984773\n","Resource group: mlops\n"]}],"execution_count":2,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core.compute import AmlCompute, ComputeTarget\r\n","from azureml.core.datastore import Datastore\r\n","from azureml.data.data_reference import DataReference\r\n","from azureml.pipeline.core import Pipeline, PipelineData\r\n","from azureml.pipeline.steps import PythonScriptStep\r\n","from azureml.core.runconfig import CondaDependencies, RunConfiguration\r\n","from azureml.core.compute_target import ComputeTargetException"],"outputs":[],"execution_count":3,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import os\r\n","\r\n","# create directory for model\r\n","model_dir = 'models'\r\n","if not os.path.isdir(model_dir):\r\n","    os.mkdir(model_dir)"],"outputs":[],"execution_count":4,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import urllib.request\r\n","\r\n","def download_model(model_name):\r\n","    # downloaded models from https://pytorch.org/tutorials/advanced/neural_style_tutorial.html are kept here\r\n","    url=\"https://pipelinedata.blob.core.windows.net/styletransfer/saved_models/\" + model_name\r\n","    local_path = os.path.join(model_dir, model_name)\r\n","    urllib.request.urlretrieve(url, local_path)"],"outputs":[],"execution_count":5,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["\r\n","from azureml.core.model import Model\r\n","mosaic_model = None\r\n","candy_model = None\r\n","\r\n","models = Model.list(workspace=ws, tags=['scenario'])\r\n","for m in models:\r\n","    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)\r\n","    if m.name == 'mosaic' and mosaic_model is None:\r\n","        mosaic_model = m\r\n","    elif m.name == 'candy' and candy_model is None:\r\n","        candy_model = m\r\n","\r\n","if mosaic_model is None:\r\n","    print('Mosaic model does not exist, registering it')\r\n","    download_model('mosaic.pth')\r\n","    mosaic_model = Model.register(model_path = os.path.join(model_dir, \"mosaic.pth\"),\r\n","                       model_name = \"mosaic\",\r\n","                       tags = {'type': \"mosaic\", 'scenario': \"Style transfer using batch inference\"},\r\n","                       description = \"Style transfer - Mosaic\",\r\n","                       workspace = ws)\r\n","else:\r\n","    print('Reusing existing mosaic model')\r\n","    \r\n","\r\n","if candy_model is None:\r\n","    print('Candy model does not exist, registering it')\r\n","    download_model('candy.pth')\r\n","    candy_model = Model.register(model_path = os.path.join(model_dir, \"candy.pth\"),\r\n","                       model_name = \"candy\",\r\n","                       tags = {'type': \"candy\", 'scenario': \"Style transfer using batch inference\"},\r\n","                       description = \"Style transfer - Candy\",\r\n","                       workspace = ws)\r\n","else:\r\n","    print('Reusing existing candy model')"],"outputs":[{"output_type":"stream","name":"stdout","text":["Name: candy \tVersion: 1 \tDescription: Style transfer - Candy {'type': 'candy', 'scenario': 'Style transfer using batch inference'}\n","Name: mosaic \tVersion: 1 \tDescription: Style transfer - Mosaic {'type': 'mosaic', 'scenario': 'Style transfer using batch inference'}\n","Reusing existing mosaic model\n","Reusing existing candy model\n"]}],"execution_count":6,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# AmlCompute\r\n","cpu_cluster_name = \"cpu-cluster\"\r\n","try:\r\n","    cpu_cluster = AmlCompute(ws, cpu_cluster_name)\r\n","    print(\"found existing cluster.\")\r\n","except ComputeTargetException:\r\n","    print(\"creating new cluster\")\r\n","    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_v2\",\r\n","                                                                    max_nodes = 1)\r\n","\r\n","    # create the cluster\r\n","    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, provisioning_config)\r\n","    cpu_cluster.wait_for_completion(show_output=True)\r\n","    \r\n","# AmlCompute\r\n","gpu_cluster_name = \"gpu-cluster\"\r\n","try:\r\n","    gpu_cluster = AmlCompute(ws, gpu_cluster_name)\r\n","    print(\"found existing cluster.\")\r\n","except ComputeTargetException:\r\n","    print(\"creating new cluster\")\r\n","    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\r\n","                                                                max_nodes = 3)\r\n","\r\n","    # create the cluster\r\n","    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\r\n","    gpu_cluster.wait_for_completion(show_output=True)"],"outputs":[{"output_type":"stream","name":"stdout","text":["found existing cluster.\n","creating new cluster\n","Creating\n","AmlCompute wait for completion finished\n","\n","Terminal state of \"Failed\" has been reached\n","\n","Provisioning errors: [{'error': {'code': 'VmSizeNotSupported', 'message': 'STANDARD_NC6 is not supported in region centralus. Please choose a different VM size.', 'details': []}}]\n","\n"]}],"execution_count":7,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["\r\n","scripts_folder = \"scripts\""],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["process_video_script_file = \"process_video.py\"\r\n","\r\n","# peek at contents\r\n","with open(os.path.join(scripts_folder, process_video_script_file)) as process_video_file:\r\n","    print(process_video_file.read())"],"outputs":[{"output_type":"stream","name":"stdout","text":["import argparse\n","import glob\n","import os\n","import subprocess\n","\n","parser = argparse.ArgumentParser(description=\"Process input video\")\n","parser.add_argument('--input_video', required=True)\n","parser.add_argument('--output_audio', required=True)\n","parser.add_argument('--output_images', required=True)\n","\n","args = parser.parse_args()\n","\n","os.makedirs(args.output_audio, exist_ok=True)\n","os.makedirs(args.output_images, exist_ok=True)\n","\n","subprocess.run(\"ffmpeg -i {} {}/video.aac\".format(args.input_video, args.output_audio),\n","               shell=True,\n","               check=True)\n","\n","subprocess.run(\"ffmpeg -i {} {}/%05d_video.jpg -hide_banner\".format(args.input_video, args.output_images),\n","               shell=True,\n","               check=True)\n"]}],"execution_count":11,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["stitch_video_script_file = \"stitch_video.py\"\r\n","\r\n","# peek at contents\r\n","with open(os.path.join(scripts_folder, stitch_video_script_file)) as stitch_video_file:\r\n","    print(stitch_video_file.read())"],"outputs":[{"output_type":"stream","name":"stdout","text":["import argparse\n","import os\n","import subprocess\n","\n","parser = argparse.ArgumentParser(description=\"Process input video\")\n","parser.add_argument('--images_dir', required=True)\n","parser.add_argument('--input_audio', required=True)\n","parser.add_argument('--output_dir', required=True)\n","\n","args = parser.parse_args()\n","\n","os.makedirs(args.output_dir, exist_ok=True)\n","\n","subprocess.run(\"ffmpeg -framerate 30 -i {}/%05d_video.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p \"\n","               \"-y {}/video_without_audio.mp4\"\n","               .format(args.images_dir, args.output_dir),\n","               shell=True, check=True)\n","\n","subprocess.run(\"ffmpeg -i {}/video_without_audio.mp4 -i {}/video.aac -map 0:0 -map 1:0 -vcodec \"\n","               \"copy -acodec copy -y {}/video_with_audio.mp4\"\n","               .format(args.output_dir, args.input_audio, args.output_dir),\n","               shell=True, check=True)\n"]}],"execution_count":12,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["\r\n","# datastore for input video\r\n","account_name = \"pipelinedata\"\r\n","video_ds = Datastore.register_azure_blob_container(ws, \"videos\", \"sample-videos\",\r\n","                                            account_name=account_name, overwrite=True)\r\n","\r\n","# the default blob store attached to a workspace\r\n","default_datastore = ws.get_default_datastore()"],"outputs":[],"execution_count":13,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# datastore for input video\r\n","account_name = \"pipelinedata\"\r\n","video_ds = Datastore.register_azure_blob_container(ws, \"videos\", \"sample-videos\",\r\n","                                            account_name=account_name, overwrite=True)\r\n","\r\n","# the default blob store attached to a workspace\r\n","default_datastore = ws.get_default_datastore()"],"outputs":[],"execution_count":14,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["video_name=os.getenv(\"STYLE_TRANSFER_VIDEO_NAME\", \"orangutan.mp4\") \r\n","orangutan_video = DataReference(datastore=video_ds,\r\n","                            data_reference_name=\"video\",\r\n","                            path_on_datastore=video_name, mode=\"download\")"],"outputs":[],"execution_count":15,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["cd = CondaDependencies()\r\n","\r\n","cd.add_channel(\"conda-forge\")\r\n","cd.add_conda_package(\"ffmpeg\")\r\n","\r\n","# Runconfig\r\n","amlcompute_run_config = RunConfiguration(conda_dependencies=cd)\r\n","amlcompute_run_config.environment.docker.base_image = \"pytorch/pytorch\"\r\n","amlcompute_run_config.environment.spark.precache_packages = False"],"outputs":[],"execution_count":16,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["ffmpeg_audio = PipelineData(name=\"ffmpeg_audio\", datastore=default_datastore)\r\n","processed_images = PipelineData(name=\"processed_images\", datastore=default_datastore)\r\n","output_video = PipelineData(name=\"output_video\", datastore=default_datastore)\r\n","\r\n","ffmpeg_images_ds_name = \"ffmpeg_images_data\"\r\n","ffmpeg_images = PipelineData(name=\"ffmpeg_images\", datastore=default_datastore)\r\n","ffmpeg_images_file_dataset = ffmpeg_images.as_dataset()\r\n","ffmpeg_images_named_file_dataset = ffmpeg_images_file_dataset.as_named_input(ffmpeg_images_ds_name)"],"outputs":[],"execution_count":17,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.pipeline.core.graph import PipelineParameter\r\n","# create a parameter for style (one of \"candy\", \"mosaic\") to transfer the images to\r\n","style_param = PipelineParameter(name=\"style\", default_value=\"mosaic\")"],"outputs":[],"execution_count":18,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["\r\n","split_video_step = PythonScriptStep(\r\n","    name=\"split video\",\r\n","    script_name=\"process_video.py\",\r\n","    arguments=[\"--input_video\", orangutan_video,\r\n","               \"--output_audio\", ffmpeg_audio,\r\n","               \"--output_images\", ffmpeg_images,\r\n","              ],\r\n","    compute_target=cpu_cluster,\r\n","    inputs=[orangutan_video],\r\n","    outputs=[ffmpeg_images, ffmpeg_audio],\r\n","    runconfig=amlcompute_run_config,\r\n","    source_directory=scripts_folder\r\n",")\r\n","\r\n","stitch_video_step = PythonScriptStep(\r\n","    name=\"stitch\",\r\n","    script_name=\"stitch_video.py\",\r\n","    arguments=[\"--images_dir\", processed_images, \r\n","               \"--input_audio\", ffmpeg_audio, \r\n","               \"--output_dir\", output_video],\r\n","    compute_target=cpu_cluster,\r\n","    inputs=[processed_images, ffmpeg_audio],\r\n","    outputs=[output_video],\r\n","    runconfig=amlcompute_run_config,\r\n","    source_directory=scripts_folder\r\n",")"],"outputs":[],"execution_count":19,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Environment\r\n","from azureml.core.runconfig import DEFAULT_GPU_IMAGE\r\n","\r\n","parallel_cd = CondaDependencies()\r\n","\r\n","parallel_cd.add_channel(\"pytorch\")\r\n","parallel_cd.add_conda_package(\"pytorch\")\r\n","parallel_cd.add_conda_package(\"torchvision\")\r\n","\r\n","styleenvironment = Environment(name=\"styleenvironment\")\r\n","styleenvironment.python.conda_dependencies=parallel_cd\r\n","styleenvironment.docker.base_image = DEFAULT_GPU_IMAGE"],"outputs":[],"execution_count":20,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.contrib.pipeline.steps import ParallelRunConfig\r\n","\r\n","parallel_run_config = ParallelRunConfig(\r\n","                    environment=styleenvironment,\r\n","                    entry_script='transform.py',\r\n","                    output_action='summary_only',\r\n","                    mini_batch_size=\"1\",\r\n","                    error_threshold=1,\r\n","                    source_directory=scripts_folder,\r\n","                    compute_target=cpu_cluster, \r\n","                    node_count=3)"],"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Parameter node_count must be between 1 and max_nodes 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-07d557939be4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0msource_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscripts_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mcompute_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_cluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     node_count=3)\n\u001b[0m","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/pipeline/steps/parallel_run_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, environment, entry_script, error_threshold, output_action, compute_target, node_count, process_count_per_node, mini_batch_size, source_directory, description, logging_level, run_invocation_timeout, input_format)\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise ValueError(\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"Parameter node_count must be between 1 and max_nodes {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 .format(self.compute_target.scale_settings.maximum_node_count))\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_invocation_timeout\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Parameter node_count must be between 1 and max_nodes 1"]}],"execution_count":24,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.contrib.pipeline.steps import ParallelRunStep\r\n","from datetime import datetime\r\n","\r\n","parallel_step_name = 'styletransfer-' + datetime.now().strftime('%Y%m%d%H%M')\r\n","\r\n","distributed_style_transfer_step = ParallelRunStep(\r\n","    name=parallel_step_name,\r\n","    inputs=[ffmpeg_images_named_file_dataset], # Input file share/blob container/file dataset\r\n","    output=processed_images,  # Output file share/blob container\r\n","    models=[mosaic_model, candy_model],\r\n","    tags = {'scenario': \"batch inference\", 'type': \"demo\"},\r\n","    properties = {'area': \"style transfer\"},\r\n","    arguments=[\"--style\", style_param],\r\n","    parallel_run_config=parallel_run_config,\r\n","    allow_reuse=True #[optional - default value True]\r\n",")"],"outputs":[],"execution_count":22,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["pipeline = Pipeline(workspace=ws, steps=[stitch_video_step])\r\n","\r\n","pipeline.validate()"],"outputs":[{"output_type":"error","ename":"TypeError","evalue":"create_module_def() got an unexpected keyword argument 'arguments'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-16dfb8bb247d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstitch_video_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/_experiment_method.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \"\"\"\n\u001b[1;32m     92\u001b[0m             \u001b[0mExperimentSubmitRegistrar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_submit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parameter %s is not recognized for Pipeline '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_email_notification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menable_email_notification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_experiment_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, name, steps, finalize, regenerate_outputs)\u001b[0m\n\u001b[1;32m   1405\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregenerate_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregenerate_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, name, steps)\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_builderStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_builderStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0madded_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madded_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1675\u001b[0m         \"\"\"\n\u001b[1;32m   1676\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;31m# just a step?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipelineStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[0;31m# delegate to correct builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_step\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0mresolved_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[0;31m# resolve run_after's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mresolve_references\u001b[0;34m(self, node_list)\u001b[0m\n\u001b[1;32m   1565\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mpeer\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step2node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_closure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m                                 \u001b[0madded_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m                                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_step\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step2node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_datastore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_node_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/contrib/pipeline/steps/parallel_run_step.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(self, graph, default_datastore, context)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \"\"\"\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParallelRunStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_datastore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BatchInferencingMetaData\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_batch_inference_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Script\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_BATCH_SCORE_MAIN_FILE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/steps/python_script_step.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(self, graph, default_datastore, context)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \"\"\"\n\u001b[1;32m    241\u001b[0m         return super(PythonScriptStep, self).create_node(\n\u001b[0;32m--> 242\u001b[0;31m             graph=graph, default_datastore=default_datastore, context=context)\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_amlcompute_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnative_shared_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/_python_script_step_base.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(self, graph, default_datastore, context)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                             \u001b[0moutput_bindings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_bindings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_defs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_defs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                             \u001b[0mallow_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_reuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                             arguments=self._annotated_arguments)\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         module_builder = _ModuleBuilder(\n","\u001b[0;31mTypeError\u001b[0m: create_module_def() got an unexpected keyword argument 'arguments'"]}],"execution_count":23,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# submit the pipeline and provide values for the PipelineParameters used in the pipeline\r\n","pipeline_run = Experiment(ws, 'styletransfer_parallel_mosaic').submit(pipeline)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# Track pipeline run progress\r\n","from azureml.widgets import RunDetails\r\n","RunDetails(pipeline_run).show()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["pipeline_run.wait_for_completion()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["def download_video(run, target_dir=None):\r\n","    stitch_run = run.find_step_run(\"stitch\")[0]\r\n","    port_data = stitch_run.get_output_data(\"output_video\")\r\n","    port_data.download(target_dir, show_progress=True)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["pipeline_run.wait_for_completion()\r\n","download_video(pipeline_run, \"output_video_mosaic\")"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["pipeline_name = \"style-transfer-batch-inference\"\r\n","print(pipeline_name)\r\n","\r\n","published_pipeline = pipeline.publish(\r\n","    name=pipeline_name, \r\n","    description=pipeline_name)\r\n","print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.pipeline.core import PublishedPipeline\r\n","\r\n","# You could retrieve all pipelines that are published, or \r\n","# just get the published pipeline object that you have the ID for.\r\n","\r\n","# Get all published pipeline objects in the workspace\r\n","all_pub_pipelines = PublishedPipeline.list(ws)\r\n","\r\n","# We will iterate through the list of published pipelines and \r\n","# use the last ID in the list for Schelue operations: \r\n","print(\"Published pipelines found in the workspace:\")\r\n","for pub_pipeline in all_pub_pipelines:\r\n","    print(\"Name:\", pub_pipeline.name,\"\\tDescription:\", pub_pipeline.description, \"\\tId:\", pub_pipeline.id, \"\\tStatus:\", pub_pipeline.status)\r\n","    if(pub_pipeline.name == pipeline_name):\r\n","        published_pipeline = pub_pipeline\r\n","\r\n","print(\"Published pipeline id: {}\".format(published_pipeline.id))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core.authentication import InteractiveLoginAuthentication\r\n","import requests\r\n","\r\n","auth = InteractiveLoginAuthentication()\r\n","aad_token = auth.get_authentication_header()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["rest_endpoint = published_pipeline.endpoint\r\n","print(\"Pipeline REST endpoing: {}\".format(rest_endpoint))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["experiment_name = 'styletransfer_parallel_candy'\r\n","response = requests.post(rest_endpoint, \r\n","                         headers=aad_token,\r\n","                         json={\"ExperimentName\": experiment_name,\r\n","                               \"ParameterAssignments\": {\"style\": \"candy\", \"aml_node_count\": 2}})\r\n","run_id = response.json()[\"Id\"]\r\n","\r\n","from azureml.pipeline.core.run import PipelineRun\r\n","published_pipeline_run_candy = PipelineRun(ws.experiments[experiment_name], run_id)\r\n","\r\n","RunDetails(published_pipeline_run_candy).show()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["published_pipeline_run_candy.wait_for_completion()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["download_video(published_pipeline_run_candy, target_dir=\"output_video_candy\""],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernel_info":{"name":"python3"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":2}